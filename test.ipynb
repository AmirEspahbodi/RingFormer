{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "class HParams:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if isinstance(value, dict):\n",
    "                # Recursively turn dictionaries into HParams\n",
    "                value = HParams(**value)\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def keys(self):\n",
    "        return self.__dict__.keys()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        setattr(self, key, value)\n",
    "\n",
    "\n",
    "def get_hparams(init=True, config_path=\"./configs/vits2_ljs_ring.json\", model_name=\"test\"):\n",
    "    # Model directory setup\n",
    "    model_dir = os.path.join(\"./logs\", model_name)\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    config_save_path = os.path.join(model_dir, \"config.json\")\n",
    "\n",
    "    if init:\n",
    "        # Read and save the configuration file\n",
    "        with open(config_path, \"r\") as f:\n",
    "            data = f.read()\n",
    "        with open(config_save_path, \"w\") as f:\n",
    "            f.write(data)\n",
    "    else:\n",
    "        # Load the saved configuration file\n",
    "        with open(config_save_path, \"r\") as f:\n",
    "            data = f.read()\n",
    "\n",
    "    config = json.loads(data)\n",
    "\n",
    "    # Create HParams object\n",
    "    hparams = HParams(**config)\n",
    "    hparams.model_dir = model_dir\n",
    "\n",
    "    # Ensure default values for model and data\n",
    "    if not hasattr(hparams, \"model\"):\n",
    "        hparams.model = HParams()\n",
    "    if not hasattr(hparams, \"data\"):\n",
    "        hparams.data = HParams()\n",
    "\n",
    "    return hparams\n",
    "\n",
    "\n",
    "# Example usage in Jupyter Notebook\n",
    "config_path = \"./configs/vits2_ljs_ring.json\"  # Specify your config file path\n",
    "model_name = \"test\"  # Specify your model name\n",
    "\n",
    "hps = get_hparams(init=True, config_path=config_path, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mel posterior encoder for VITS2\n",
      "Using transformer flows pre_conv for VITS2\n",
      "Using normal encoder for VITS1\n",
      "Using noise scaled MAS for VITS2\n",
      "Low pass filter created, time used = 0.0007 seconds\n",
      "num_octave =  9\n",
      "No early downsampling is required, downsample_factor =  1\n",
      "Early downsampling filter created,                         time used = 0.0000 seconds\n",
      "CQT kernels created, time used = 0.0023 seconds\n",
      "Low pass filter created, time used = 0.0002 seconds\n",
      "num_octave =  9\n",
      "No early downsampling is required, downsample_factor =  1\n",
      "Early downsampling filter created,                         time used = 0.0000 seconds\n",
      "CQT kernels created, time used = 0.0038 seconds\n",
      "Low pass filter created, time used = 0.0002 seconds\n",
      "num_octave =  9\n",
      "No early downsampling is required, downsample_factor =  1\n",
      "Early downsampling filter created,                         time used = 0.0000 seconds\n",
      "CQT kernels created, time used = 0.0053 seconds\n",
      "./logs/test/G_352000.pth\n",
      "INFO:root:Loaded checkpoint './logs/test/G_352000.pth' (iteration 1769)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import torch\n",
    "import itertools\n",
    "from text.symbols import symbols\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from models import (\n",
    "    SynthesizerTrn,\n",
    "    MultiPeriodDiscriminator,\n",
    "    MultiScaleSubbandCQTDiscriminator,\n",
    "    AVAILABLE_FLOW_TYPES,\n",
    ")\n",
    "if (\n",
    "    \"use_mel_posterior_encoder\" in hps.model.keys()\n",
    "    and hps.model.use_mel_posterior_encoder == True\n",
    "):\n",
    "    print(\"Using mel posterior encoder for VITS2\")\n",
    "    posterior_channels = 80  # vits2\n",
    "    hps.data.use_mel_posterior_encoder = True\n",
    "else:\n",
    "    print(\"Using lin posterior encoder for VITS1\")\n",
    "    posterior_channels = hps.data.filter_length // 2 + 1\n",
    "    hps.data.use_mel_posterior_encoder = False\n",
    "if (\n",
    "    \"use_transformer_flows\" in hps.model.keys()\n",
    "    and hps.model.use_transformer_flows == True\n",
    "):\n",
    "    use_transformer_flows = True\n",
    "    transformer_flow_type = hps.model.transformer_flow_type\n",
    "    print(f\"Using transformer flows {transformer_flow_type} for VITS2\")\n",
    "    assert (\n",
    "        transformer_flow_type in AVAILABLE_FLOW_TYPES\n",
    "    ), f\"transformer_flow_type must be one of {AVAILABLE_FLOW_TYPES}\"\n",
    "else:\n",
    "    print(\"Using normal flows for VITS1\")\n",
    "    use_transformer_flows = False\n",
    "\n",
    "if (\n",
    "    \"use_spk_conditioned_encoder\" in hps.model.keys()\n",
    "    and hps.model.use_spk_conditioned_encoder == True\n",
    "):\n",
    "    if hps.data.n_speakers == 0:\n",
    "        print(\"Warning: use_spk_conditioned_encoder is True but n_speakers is 0\")\n",
    "    print(\n",
    "        \"Setting use_spk_conditioned_encoder to False as model is a single speaker model\"\n",
    "    )\n",
    "    use_spk_conditioned_encoder = False\n",
    "else:\n",
    "    print(\"Using normal encoder for VITS1\")\n",
    "    use_spk_conditioned_encoder = False\n",
    "\n",
    "if (\n",
    "    \"use_noise_scaled_mas\" in hps.model.keys()\n",
    "    and hps.model.use_noise_scaled_mas == True\n",
    "):\n",
    "    print(\"Using noise scaled MAS for VITS2\")\n",
    "    use_noise_scaled_mas = True\n",
    "    mas_noise_scale_initial = 0.01\n",
    "    noise_scale_delta = 2e-6\n",
    "else:\n",
    "    print(\"Using normal MAS for VITS1\")\n",
    "    use_noise_scaled_mas = False\n",
    "    mas_noise_scale_initial = 0.0\n",
    "    noise_scale_delta = 0.0\n",
    "\n",
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    posterior_channels,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    mas_noise_scale_initial=mas_noise_scale_initial,\n",
    "    noise_scale_delta=noise_scale_delta,\n",
    "    **hps.model,\n",
    ").cuda(0)\n",
    "net_d = MultiPeriodDiscriminator(hps.model.use_spectral_norm).cuda(0)\n",
    "net_cqtd = MultiScaleSubbandCQTDiscriminator(hps).cuda(0)\n",
    "\n",
    "optim_g = torch.optim.AdamW(\n",
    "    net_g.parameters(),\n",
    "    hps.train.learning_rate,\n",
    "    betas=hps.train.betas,\n",
    "    eps=hps.train.eps,\n",
    ")\n",
    "optim_d = torch.optim.AdamW(\n",
    "    itertools.chain(net_d.parameters(), net_cqtd.parameters()),\n",
    "    hps.train.learning_rate,\n",
    "    betas=hps.train.betas,\n",
    "    eps=hps.train.eps,\n",
    ")\n",
    "\n",
    "try:\n",
    "    _, _, _, epoch_str = utils.load_checkpoint(\n",
    "        utils.latest_checkpoint_path(hps.model_dir, \"G_*.pth\"), net_g, optim_g\n",
    "    )\n",
    "except:\n",
    "    print(\"error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ring_conformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
